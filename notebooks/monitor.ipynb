{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_random_talks', 1448),\n",
       " ('_meetings', 1350),\n",
       " ('theory_and_practice', 1322),\n",
       " ('deep_learning', 1320),\n",
       " ('lang_python', 1305),\n",
       " ('interesting_links', 1289),\n",
       " ('_jobs', 1273),\n",
       " ('edu_courses', 1177),\n",
       " ('kaggle_crackers', 1155),\n",
       " ('nlp', 1155)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"../data/mar_12_2015-apr_4_2019\")\n",
    "\n",
    "channels = os.listdir(data_path)\n",
    "channels_counts = Counter({\n",
    "    c: len(os.listdir(data_path / c)) for c in channels\n",
    "    if not c.endswith(\".json\")\n",
    "})\n",
    "channels_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Jobs analytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "jobs_data_path = data_path / \"_top_jobs\"\n",
    "\n",
    "dates = [datetime.datetime.strptime(d.split('.')[0], \"%Y-%m-%d\") \n",
    "         for d in os.listdir(jobs_data_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2019: 8, 2018: 11})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top years\n",
    "Counter((d.year for d in dates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 4), (12, 3), (2, 3), (8, 3), (11, 2), (1, 1), (9, 1), (4, 1), (7, 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top months\n",
    "Counter((d.month for d in dates)).most_common(12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# select vacancies from 2019\n",
    "\n",
    "files_to_use = [f\"{d.strftime('%Y-%m-%d')}.json\" \n",
    "                    for d in dates if d.year == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_salary_from_top_job(data: dict, city=\":spb:\"):\n",
    "    rlist = []\n",
    "    for line in data[\"text\"].split(\"\\n\"):\n",
    "        if city in line:\n",
    "            if \":fork\" in line:\n",
    "                rlist.append((line,\n",
    "                              re.findall(\"\\*[A-Za-zа-яА-Я ]+\\* by\", line),\n",
    "                              [*map(int, re.findall(r\"[0-9]+\", line.split(\":fork:\")[1]))]))\n",
    "            \n",
    "    return rlist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(jobs_data_path / files_to_use[0]) as f:\n",
    "    job_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':cryptoparrot: *ODS дайджест вакансий:* 1 января — 16 января 2019 :moneyparrot:',\n",
       " '',\n",
       " '*iPavlov*, Москва :default-city: : *Python программист* by <@U8EPE4WG6> :fork: *125-165k*',\n",
       " '*Задачи:* Создавать решения для конечных пользователей, адаптировать существующие алгоритмы и разрабатывать новые для решения прикладных задач',\n",
       " '*Требования:*  :python: :neuralnet:, плюсом :tensorflow: :nlp: контрибьюция в open-source проекты',\n",
       " '<https://opendatascience.slack.com/archives/C04DA5FUF/p1546213578476000>',\n",
       " '',\n",
       " '*FaceChain*, Санкт-Петербург :spb: : *Data Scientist* by <@UD8RBM06S> :fork: *80-200k*',\n",
       " '*Задачи:* Детекция и распознование лиц, антиспуффинг',\n",
       " '*Требования:*  :python: :pytorch: OpenCV',\n",
       " '<https://opendatascience.slack.com/archives/C04DA5FUF/p1547043026689000>',\n",
       " '',\n",
       " '*Институт развития интернета*, Москва :default-city:  : *Data Scientist* by <@U86E2ECGZ> :fork: *100-120k*',\n",
       " '*Задачи:* Проводить различные исследования открытых данных',\n",
       " '*Требования:*  Опыт в анализе данных и машинном обучении, плюсом знания фронтэнда',\n",
       " '<https://opendatascience.slack.com/archives/C04DA5FUF/p1547152228791000>',\n",
       " '',\n",
       " '*<http://ivi.ru|ivi.ru>*, Москва :default-city:  : *Deep Learning Engineer* by <@U3W85TQBE> :fork: *140-200k*',\n",
       " '*Задачи:* Преобразование видеоконтента в 4К и HDR, выделение хайлайтов в видео, создание embedding-ов картинок и видео',\n",
       " '*Требования:*  :python: :tensorflow: :panda: scikit-learn, Linux (basd, sed, grep), английский язык, плюсом :sql: :hadoop: :spark: Hive, Yarn',\n",
       " '<https://opendatascience.slack.com/archives/C04DA5FUF/p1547207360813300>',\n",
       " '',\n",
       " '*C7 Техлаб*, Москва :default-city:  : *MIddle/Senior Machine Learning Engineer* by <@U3TF60E65> :fork: *150-250k/250-350k*',\n",
       " '*Задачи:* Подбирать оптимальный набор алгоритмов для задачи, стрить пайплайны построения признаков и обучения моделей, разрабатывать архитектуру решений, оптимизировать решения DS-ов, выводить решения в прод',\n",
       " '*Требования:* :python: :cpp:, плюсом (:scala::java:), :kubernetes:, :aws: Lambda, опыт работы DE/DS/SE от 3 лет, опыт оптимизации ML моделей, Linux (bash, sed, awk)',\n",
       " '<https://opendatascience.slack.com/archives/C04DA5FUF/p1547212590820100>',\n",
       " '',\n",
       " '*QIWI*, Москва :default-city:  : *Lead Data Scientist* by <@U3JUB9PB9> :fork: *150-210k*',\n",
       " '*Задачи:* Курировать команду аналитиков, разработка модели для выявления клиентов, осуществляющих сомнительную деятельность',\n",
       " '*Требования:* :python: :panda::tensorflow: :keras:  scikit-learn, seaborn, networkx, практический опыт ML, :sql: BI :tableau:, Big data',\n",
       " '<https://opendatascience.slack.com/archives/C04DA5FUF/p1547466564895000>',\n",
       " '',\n",
       " '*Yousician*, Helsinki :flag-fi:: *Data Engineer* by <@UFDAR7JTT> :fork: *€3.5-5k*',\n",
       " '*Задачи:* Develop and maintain data pipeline, improve the scaling, optimization, tests and internal tools to enhance data quality &amp; reliability',\n",
       " '*Требования:* Experience in building or maintaining DWH or ETL pipeline, hands-on experience with DWH technologies (:hadoop::spark:, Redshift, Druid, Apache Drill), experience with TDD in :python: :sql: , Linux, :aws: GCP, Airflow',\n",
       " '<https://opendatascience.slack.com/archives/C04DA5FUF/p1547556463029400>',\n",
       " '',\n",
       " '*Jetlex*, Москва :default-city:: *NLP Data Scientist* by <@UBUCAUEFJ> :fork: *200-260k*',\n",
       " '*Задачи:* OCR + Fact Extraction из юридических документов',\n",
       " '*Требования:* опыт DS/NLP от 2 лет, опыт применения :xgboost: :neuralnet: , плюсом знания в CV и  OCR',\n",
       " '<https://opendatascience.slack.com/archives/C04DA5FUF/p1547577905063700>',\n",
       " '',\n",
       " '*Сбербанк*, Москва :default-city:: *Data Scientist* by <@U5GB71SCX> :fork: *120-200k*',\n",
       " '*Задачи:*  Выявление именных сущностей, дедубликация, тематическое моделирование, классификация новостей, выявление событий в новости',\n",
       " '*Требования:* :python: :pytorch: :tensorflow: scikit-learn, Linux, Git, опыт DS от года, плюсом знания в NLP',\n",
       " '<https://opendatascience.slack.com/archives/C04DA5FUF/p1547627021079000>']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_dict[0][\"text\"].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stats = []\n",
    "for job_file in files_to_use:\n",
    "    with open(jobs_data_path / job_file) as f:\n",
    "        job_dict = json.load(f)\n",
    "    for d in job_dict:\n",
    "        stats.extend(extract_salary_from_top_job(d, \":default-city:\"))\n",
    "        stats.extend(extract_salary_from_top_job(d, \":spb:\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('*iPavlov*, Москва :default-city: : *Python программист* by <@U8EPE4WG6> :fork: *125-165k*',\n",
       "  ['*Python программист* by'],\n",
       "  [125, 165]),\n",
       " ('*Институт развития интернета*, Москва :default-city:  : *Data Scientist* by <@U86E2ECGZ> :fork: *100-120k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [100, 120]),\n",
       " ('*<http://ivi.ru|ivi.ru>*, Москва :default-city:  : *Deep Learning Engineer* by <@U3W85TQBE> :fork: *140-200k*',\n",
       "  ['*Deep Learning Engineer* by'],\n",
       "  [140, 200]),\n",
       " ('*C7 Техлаб*, Москва :default-city:  : *MIddle/Senior Machine Learning Engineer* by <@U3TF60E65> :fork: *150-250k/250-350k*',\n",
       "  [],\n",
       "  [150, 250, 250, 350]),\n",
       " ('*QIWI*, Москва :default-city:  : *Lead Data Scientist* by <@U3JUB9PB9> :fork: *150-210k*',\n",
       "  ['*Lead Data Scientist* by'],\n",
       "  [150, 210]),\n",
       " ('*Jetlex*, Москва :default-city:: *NLP Data Scientist* by <@UBUCAUEFJ> :fork: *200-260k*',\n",
       "  ['*NLP Data Scientist* by'],\n",
       "  [200, 260]),\n",
       " ('*Сбербанк*, Москва :default-city:: *Data Scientist* by <@U5GB71SCX> :fork: *120-200k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [120, 200]),\n",
       " ('*FaceChain*, Санкт-Петербург :spb: : *Data Scientist* by <@UD8RBM06S> :fork: *80-200k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [80, 200]),\n",
       " ('*Skyeng* , Москва :default-city: / удалёнка :palm_tree:: *Специалист по анализу видео* by <@U5G25HMS9> :fork: *150-250k*',\n",
       "  ['*Специалист по анализу видео* by'],\n",
       "  [150, 250]),\n",
       " ('*Okko*, Санкт-Петербург :spb: : *Data Scientist* by <@U6YTYEJR4> :fork: *100-160k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [100, 160]),\n",
       " ('*Wrike*, Санкт-Петербург :spb: : *Data Scientist* by <@U8CMHHBU2> :fork: *150-250k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [150, 250]),\n",
       " ('*Segmento*, Санкт-Петербург :spb: : *Middle/ Senior Data Scientist* by <@U9B17DQUV> :fork: *120-170k/ 180-230k*',\n",
       "  [],\n",
       "  [120, 170, 180, 230]),\n",
       " ('*VK*,  + Москва :default-city:: *Senior Machine Learning Research Engineer* by <@U04FHEY0M> :fork: *200-300k*',\n",
       "  ['*Senior Machine Learning Research Engineer* by'],\n",
       "  [200, 300]),\n",
       " ('*Poteha Labs* , Москва :default-city: : *Middle ML Engineer* by <@U17S9F6KV> :fork: *120-200k*',\n",
       "  ['*Middle ML Engineer* by'],\n",
       "  [120, 200]),\n",
       " ('*X5* , Москва :default-city: : *Data Scientist* by <@U2LGQMC4D> :fork: *200-240k + 60/72k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [200, 240, 60, 72]),\n",
       " ('*Gazprom media* , Москва :default-city: : *Middle Data Scientist* by <@U2AJE72Q6> :fork: *100-170k*',\n",
       "  ['*Middle Data Scientist* by'],\n",
       "  [100, 170]),\n",
       " ('*SEMrush*, Санкт-Петербург :spb: : *Data Scientist* by <@U4BBNMQ03> :fork: *150-180k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [150, 180]),\n",
       " ('*ВКонтакте*, Санкт-Петербург :spb: : *Machine Learning Research Engineer* by <@U099YUD1S> :fork: *100-300k*',\n",
       "  ['*Machine Learning Research Engineer* by'],\n",
       "  [100, 300]),\n",
       " ('*РИА Новости*, Москва :default-city: : *Data Scientist* by <@U7CAU0GMU> :fork: *80-130k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [80, 130]),\n",
       " ('*AR/VR Лаборатория Сбербанка*, Москва :default-city: : *Senior IOS-разработчик со знанием CV и DL* by <@UFJH6JQ4E> :fork: *230-300k*',\n",
       "  [],\n",
       "  [230, 300]),\n",
       " ('*Тинькофф Банк*, Москва :default-city: : *Junior Data Scientist* by <@U2FM0GQUE> :fork: *60-100k*',\n",
       "  ['*Junior Data Scientist* by'],\n",
       "  [60, 100]),\n",
       " ('*Яндекс*, Москва :default-city: : *Разработчик систем калибровок* by <@U0VLLEKGX> :fork: *140-300k*',\n",
       "  ['*Разработчик систем калибровок* by'],\n",
       "  [140, 300]),\n",
       " ('*Huawei*, Москва :default-city: : *Video / Camera AI Expert* by <@U1UJG8QFJ> :fork: *60-300k*',\n",
       "  [],\n",
       "  [60, 300]),\n",
       " ('*Kinetik*, Москва :default-city: : *Data Scientist* by <@UDXM2H6MA> :fork: *150-200k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [150, 200]),\n",
       " ('*X5 Retail Group*, Москва :default-city: : *Computational Linguist* by <@U2LGQMC4D> :fork: *150к-250к + 45-75k*',\n",
       "  ['*Computational Linguist* by'],\n",
       "  [150, 250, 45, 75]),\n",
       " ('*Алгомост* , Москва :default-city: : *Data Scientist* by <@UBK9444P5> :fork: *120-200k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [120, 200]),\n",
       " ('*ID R&amp;D* , Санкт-Петербург :spb: : *ML инженер* by <@U78BSPA4X> :fork: *150-300k*',\n",
       "  ['*ML инженер* by'],\n",
       "  [150, 300])]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "include_job_titles = {\"Data Scientist\", \"ML\", \"Machine Learning\", \"Middle\"}\n",
    "exclude_job_titles = {\"Senior\", \"Junior\", \"Lead\", \"Video\", \"калибровок\"}\n",
    "\n",
    "filtered_jobs = []\n",
    "\n",
    "for job in stats:\n",
    "    exclude = False\n",
    "    for ejt in exclude_job_titles:\n",
    "        exclude = ejt in job[0]\n",
    "        if exclude:\n",
    "            break\n",
    "    if exclude:\n",
    "        continue\n",
    "    \n",
    "    filtered_jobs.append(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('*iPavlov*, Москва :default-city: : *Python программист* by <@U8EPE4WG6> :fork: *125-165k*',\n",
       "  ['*Python программист* by'],\n",
       "  [125, 165]),\n",
       " ('*Институт развития интернета*, Москва :default-city:  : *Data Scientist* by <@U86E2ECGZ> :fork: *100-120k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [100, 120]),\n",
       " ('*<http://ivi.ru|ivi.ru>*, Москва :default-city:  : *Deep Learning Engineer* by <@U3W85TQBE> :fork: *140-200k*',\n",
       "  ['*Deep Learning Engineer* by'],\n",
       "  [140, 200]),\n",
       " ('*Jetlex*, Москва :default-city:: *NLP Data Scientist* by <@UBUCAUEFJ> :fork: *200-260k*',\n",
       "  ['*NLP Data Scientist* by'],\n",
       "  [200, 260]),\n",
       " ('*Сбербанк*, Москва :default-city:: *Data Scientist* by <@U5GB71SCX> :fork: *120-200k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [120, 200]),\n",
       " ('*FaceChain*, Санкт-Петербург :spb: : *Data Scientist* by <@UD8RBM06S> :fork: *80-200k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [80, 200]),\n",
       " ('*Skyeng* , Москва :default-city: / удалёнка :palm_tree:: *Специалист по анализу видео* by <@U5G25HMS9> :fork: *150-250k*',\n",
       "  ['*Специалист по анализу видео* by'],\n",
       "  [150, 250]),\n",
       " ('*Okko*, Санкт-Петербург :spb: : *Data Scientist* by <@U6YTYEJR4> :fork: *100-160k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [100, 160]),\n",
       " ('*Wrike*, Санкт-Петербург :spb: : *Data Scientist* by <@U8CMHHBU2> :fork: *150-250k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [150, 250]),\n",
       " ('*Poteha Labs* , Москва :default-city: : *Middle ML Engineer* by <@U17S9F6KV> :fork: *120-200k*',\n",
       "  ['*Middle ML Engineer* by'],\n",
       "  [120, 200]),\n",
       " ('*X5* , Москва :default-city: : *Data Scientist* by <@U2LGQMC4D> :fork: *200-240k + 60/72k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [200, 240, 60, 72]),\n",
       " ('*Gazprom media* , Москва :default-city: : *Middle Data Scientist* by <@U2AJE72Q6> :fork: *100-170k*',\n",
       "  ['*Middle Data Scientist* by'],\n",
       "  [100, 170]),\n",
       " ('*SEMrush*, Санкт-Петербург :spb: : *Data Scientist* by <@U4BBNMQ03> :fork: *150-180k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [150, 180]),\n",
       " ('*ВКонтакте*, Санкт-Петербург :spb: : *Machine Learning Research Engineer* by <@U099YUD1S> :fork: *100-300k*',\n",
       "  ['*Machine Learning Research Engineer* by'],\n",
       "  [100, 300]),\n",
       " ('*РИА Новости*, Москва :default-city: : *Data Scientist* by <@U7CAU0GMU> :fork: *80-130k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [80, 130]),\n",
       " ('*Kinetik*, Москва :default-city: : *Data Scientist* by <@UDXM2H6MA> :fork: *150-200k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [150, 200]),\n",
       " ('*X5 Retail Group*, Москва :default-city: : *Computational Linguist* by <@U2LGQMC4D> :fork: *150к-250к + 45-75k*',\n",
       "  ['*Computational Linguist* by'],\n",
       "  [150, 250, 45, 75]),\n",
       " ('*Алгомост* , Москва :default-city: : *Data Scientist* by <@UBK9444P5> :fork: *120-200k*',\n",
       "  ['*Data Scientist* by'],\n",
       "  [120, 200]),\n",
       " ('*ID R&amp;D* , Санкт-Петербург :spb: : *ML инженер* by <@U78BSPA4X> :fork: *150-300k*',\n",
       "  ['*ML инженер* by'],\n",
       "  [150, 300])]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "min_forks = [fj[2][0] for fj in filtered_jobs]\n",
    "max_forks = [fj[2][1] for fj in filtered_jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121.66666666666667, 231.66666666666666)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spb only\n",
    "np.mean(min_forks), np.mean(max_forks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135.0, 198.84615384615384)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# msk only\n",
    "np.mean(min_forks), np.mean(max_forks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130.78947368421052, 209.21052631578948)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# msk and spb\n",
    "np.mean(min_forks), np.mean(max_forks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
